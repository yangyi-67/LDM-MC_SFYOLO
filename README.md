# **LDM-MC-SFYOLO: A Synergistic Framework for Source-Free Domain Adaptive Object Detection via Latent Diffusion and Uncertainty Estimation**


## **ğŸ“– Overview**

LDM-MC-SFYOLO is a novel Source-Free Domain Adaptation (SFDA) framework designed to adapt one-stage object detectors to adverse weather conditions (e.g., dense fog) without accessing original source data.



The framework introduces two synergistic innovations:


Dynamic LDM Augmentation: Replaces static style transfer by leveraging a frozen pre-trained Latent Diffusion Model (LDM). It uses a dynamic prompt library derived from target domain statistics (via Dark Channel Prior) to synthesize fine-grained and diverse samples in a zero-shot manner.

Uncertainty-Aware Pseudo-Labeling: Integrates Monte Carlo (MC) Dropout to quantify epistemic uncertainty by fusing classification and localization variances into a composite metric. A dual-threshold filtering strategy is then employed to effectively eliminate Overconfident Errors (OEs) and retain Well-Calibrated Predictions (WCPs).

This architecture establishes a mutually reinforcing closed loop of "Dynamic Generation and Uncertainty Verification".


## ğŸ“‚ Project Structure

The repository is organized to highlight the core contributions:

```text
LDM-MC-SFYOLO/
â”œâ”€â”€ TargetAugment/         # Target Augmentation Module (TAM)
â”‚   â”œâ”€â”€ enhance_ldm.py    # [Core] LDM-based dynamic style generation
â”‚   â””â”€â”€ enhance_vgg16.py  # VGG-based style transfer (Baseline)
â”œâ”€â”€ utils/                 # Utility functions and core logic
â”‚   â”œâ”€â”€ mc_dropout.py     # [Core] MC Dropout & uncertainty estimation
â”‚   â””â”€â”€ loss.py           # Modified YOLOv5 loss function for SFDA
â”œâ”€â”€ models/                # Architecture definitions
â”‚   â”œâ”€â”€ yolo.py           # YOLOv5 model construction
â”‚   â””â”€â”€ yolov5l.yaml      # Configuration for the Large backbone
â”œâ”€â”€ run_adaptation.py     # [Main] Entry point for SFDA training
â”œâ”€â”€ run_pretrain.py       # Script for source-domain pre-training
â””â”€â”€ requirements.txt      # Environment dependencies
```

## **ğŸ› ï¸ Installation**

1. **Clone the Repository:**ï¼š  
   git clone https://github.com/yangyi-67/LDM-MC_SFYOLO.git
   cd LDM-MC_SFYOLO

2. **Create Environment**ï¼š  
   conda create \-n sfyolo python=3.8 \-y  
   conda activate sfyolo

3. **Install Dependencies**ï¼š  
   \# We recommend using PyTorch 2.0+ and CUDA 11.8+ for LDM inference.
    pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
    pip install -r requirements.txt

## **ğŸš€ Quick Start**

### **1\.Data Preparation**

Organize your datasets (Cityscapes, Foggy Cityscapes, KITTI, Sim10k) as follows:ï¼š
```text
datasets/
â”œâ”€â”€ Cityscapes/
â”œâ”€â”€ Foggy_Cityscapes/
â”œâ”€â”€ KITTI/
â””â”€â”€ Sim10k/
```

### **2\. Source Pre-training**
Train a baseline model on the source domain:
python run_pretrain.py --weights yolov5s.pt --data configs/source_cityscapes.yaml --imgsz 960 --epochs 100


### **3\. Source-Free Domain Adaptation**
Launch the adaptation process using the synergistic frameworkï¼š

python run_adaptation.py \
    --weights path/to/source_model.pt \
    --data configs/target_foggy_cityscapes.yaml \
    --ta_method ldm \
    --ldm_strength 0.35 \
    --mc_dropout --mc_T 10 \
    --conf_thres 0.4 --iou_thres 0.3 \
    --teacher_alpha 0.999 \
    --SSM_alpha 0.0 \
    --batch-size 16 \
    --device 0


## **ğŸ™ Acknowledgments**
We thank the authors of YOLOv5, SF-YOLO, and HuggingFace Diffusers for their excellent open-source contributions!

## **ğŸ“§ Contact**
For any questions, please open an issue or contact: s202420211022@stu.tyust.edu.cn.
